




























































































































































































































































































































epoch: 356, loss: 0.35, time: 1.34:  89%|██████████████▏ | 356/400 [11:40<01:26,  1.97s/it]
Traceback (most recent call last):
  File "src/main.py", line 86, in <module>
    main()
  File "src/main.py", line 67, in main
    trained_model = run_server(dataset, num_clients=args.c, epochs=args.epochs,
  File "/home/abenzaamia/NeuCF/federated/src/server.py", line 35, in run_server
    trained_weights = training_process(server_model, clients, num_clients, epochs, local_epochs, dataset, args)
  File "/home/abenzaamia/NeuCF/federated/src/federeco/train.py", line 66, in training_process
    w, loss = single_train_round(server_model, clients, local_epochs)
  File "/home/abenzaamia/NeuCF/federated/src/federeco/train.py", line 110, in single_train_round
    weights, loss = client.train(server_model_copy, local_epochs)
  File "/home/abenzaamia/NeuCF/federated/src/client.py", line 51, in train
    optimizer.step()
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/optim/adam.py", line 141, in step
    adam(
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/optim/adam.py", line 281, in adam
    func(params,
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/optim/adam.py", line 345, in _single_tensor_adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)
KeyboardInterrupt